{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image to Cartoon Converter\n",
    "### Project: Converting Images to Cartoon Styles Using Computer Vision\n",
    "\n",
    "This notebook demonstrates 5 different cartoon conversion techniques using OpenCV and image processing algorithms.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "# Set matplotlib to display images inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Configure plot size\n",
    "plt.rcParams['figure.figsize'] = (20, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Cartoon Conversion Functions\n",
    "\n",
    "### A. Edge Preserving Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_preserving(img):\n",
    "    \"\"\"Edge Preserving Cartoon Effect\"\"\"\n",
    "    # Smooth the image while preserving edges\n",
    "    smooth = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "    \n",
    "    # Convert to grayscale for edge detection\n",
    "    gray = cv2.cvtColor(smooth, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.medianBlur(gray, 5)\n",
    "    \n",
    "    # Detect edges using adaptive threshold\n",
    "    edges = cv2.adaptiveThreshold(\n",
    "        gray, 255, \n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY, 9, 2\n",
    "    )\n",
    "    \n",
    "    # Apply another bilateral filter for color\n",
    "    color = cv2.bilateralFilter(img, 9, 200, 200)\n",
    "    \n",
    "    # Combine edges with color\n",
    "    return cv2.bitwise_and(color, color, mask=edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Color Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_quantization(img):\n",
    "    \"\"\"Color Quantization Cartoon Effect\"\"\"\n",
    "    # Reshape image to a list of pixels\n",
    "    data = np.float32(img).reshape((-1, 3))\n",
    "    \n",
    "    # Apply K-means clustering to reduce colors\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 0.001)\n",
    "    _, labels, centers = cv2.kmeans(\n",
    "        data, 8, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS\n",
    "    )\n",
    "    \n",
    "    # Reconstruct image with quantized colors\n",
    "    centers = np.uint8(centers)\n",
    "    quantized = centers[labels.flatten()].reshape(img.shape)\n",
    "    \n",
    "    # Edge detection\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.medianBlur(gray, 5)\n",
    "    edges = cv2.adaptiveThreshold(\n",
    "        gray, 255,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY, 9, 2\n",
    "    )\n",
    "    \n",
    "    # Combine quantized colors with edges\n",
    "    return cv2.bitwise_and(quantized, quantized, mask=edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Stylization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stylization(img):\n",
    "    \"\"\"Stylization Cartoon Effect\"\"\"\n",
    "    return cv2.stylization(img, sigma_s=150, sigma_r=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Pencil Sketch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pencil_sketch(img):\n",
    "    \"\"\"Pencil Sketch Cartoon Effect\"\"\"\n",
    "    _, sketch = cv2.pencilSketch(\n",
    "        img, \n",
    "        sigma_s=60, \n",
    "        sigma_r=0.07, \n",
    "        shade_factor=0.05\n",
    "    )\n",
    "    return sketch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Advanced Cartoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_cartoon(img):\n",
    "    \"\"\"Advanced Cartoon Effect\"\"\"\n",
    "    # Multiple passes of bilateral filtering\n",
    "    smooth = img.copy()\n",
    "    for _ in range(3):\n",
    "        smooth = cv2.bilateralFilter(smooth, 9, 75, 75)\n",
    "    \n",
    "    # Color quantization with more clusters\n",
    "    data = np.float32(smooth).reshape((-1, 3))\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 0.001)\n",
    "    _, labels, centers = cv2.kmeans(\n",
    "        data, 12, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS\n",
    "    )\n",
    "    \n",
    "    centers = np.uint8(centers)\n",
    "    quantized = centers[labels.flatten()].reshape(img.shape)\n",
    "    \n",
    "    # Edge detection with larger kernel\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.medianBlur(gray, 7)\n",
    "    edges = cv2.adaptiveThreshold(\n",
    "        gray, 255,\n",
    "        cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "        cv2.THRESH_BINARY, 9, 3\n",
    "    )\n",
    "    \n",
    "    return cv2.bitwise_and(quantized, quantized, mask=edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Model Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"Edge Preserving\": edge_preserving,\n",
    "    \"Color Quantization\": color_quantization,\n",
    "    \"Stylization\": stylization,\n",
    "    \"Pencil Sketch\": pencil_sketch,\n",
    "    \"Advanced Cartoon\": advanced_cartoon\n",
    "}\n",
    "\n",
    "print(f\"Total Models Available: {len(MODELS)}\")\n",
    "print(\"Models:\", list(MODELS.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load and Process Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CHANGE THIS LINE TO YOUR IMAGE PATH ==========\n",
    "image_path = 'your_image.jpg'  # ← Put your image filename here\n",
    "# =========================================================\n",
    "\n",
    "# Load the image\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "original = np.array(image)\n",
    "\n",
    "# Convert RGB to BGR (OpenCV format)\n",
    "img_cv = cv2.cvtColor(original, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Display original image\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(original)\n",
    "plt.title(\"Original Image\", fontsize=16, fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Image loaded successfully!\")\n",
    "print(f\"Image size: {original.shape[1]}x{original.shape[0]} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Apply All Cartoon Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store results\n",
    "results = {\"Original\": original}\n",
    "\n",
    "# Apply each cartoon model\n",
    "print(\"Processing image with all cartoon models...\\n\")\n",
    "\n",
    "for name, func in MODELS.items():\n",
    "    print(f\"Applying {name}...\")\n",
    "    # Apply the cartoon function\n",
    "    output = func(img_cv)\n",
    "    # Convert back to RGB for display\n",
    "    results[name] = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print(\"\\n✓ All models processed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Display All Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots for all images\n",
    "fig, axes = plt.subplots(1, 6, figsize=(24, 6))\n",
    "fig.suptitle('Image to Cartoon Conversion Results', fontsize=20, fontweight='bold', y=1.02)\n",
    "\n",
    "# Display each result\n",
    "for idx, (name, img) in enumerate(results.items()):\n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].set_title(name, fontsize=14, fontweight='bold', pad=10)\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Individual Cartoon Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder if it doesn't exist\n",
    "output_folder = 'cartoon_outputs'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Save each result\n",
    "print(f\"Saving images to '{output_folder}/' folder...\\n\")\n",
    "\n",
    "for name, img in results.items():\n",
    "    filename = f\"{name.lower().replace(' ', '_')}.png\"\n",
    "    filepath = os.path.join(output_folder, filename)\n",
    "    Image.fromarray(img).save(filepath)\n",
    "    print(f\"✓ Saved: {filename}\")\n",
    "\n",
    "print(f\"\\n✓ All images saved successfully in '{output_folder}/' folder!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create ZIP Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ZIP file with all cartoon outputs\n",
    "zip_filename = 'all_cartoon_outputs.zip'\n",
    "\n",
    "print(f\"Creating ZIP archive: {zip_filename}\\n\")\n",
    "\n",
    "with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zip_file:\n",
    "    for name, img in results.items():\n",
    "        if name != \"Original\":  # Skip original image\n",
    "            # Convert to bytes\n",
    "            img_buffer = BytesIO()\n",
    "            Image.fromarray(img).save(img_buffer, format='PNG')\n",
    "            \n",
    "            # Add to ZIP\n",
    "            filename = f\"{name.lower().replace(' ', '_')}.png\"\n",
    "            zip_file.writestr(filename, img_buffer.getvalue())\n",
    "            print(f\"✓ Added to ZIP: {filename}\")\n",
    "\n",
    "print(f\"\\n✓ ZIP archive created: {zip_filename}\")\n",
    "print(f\"✓ Total size: {os.path.getsize(zip_filename) / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "This project implements 5 cartoon conversion techniques:\n",
    "- Edge Preserving: Bilateral filtering + edge detection\n",
    "- Color Quantization: K-means clustering (8 colors)\n",
    "- Stylization: OpenCV stylization filter\n",
    "- Pencil Sketch: Pencil sketch algorithm\n",
    "- Advanced Cartoon: Multi-pass filtering + 12-cluster K-means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Display Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== CUSTOMIZE COMPARISON ==========\n",
    "model1 = \"Edge Preserving\"      # ← Change this\n",
    "model2 = \"Advanced Cartoon\"     # ← Change this\n",
    "# ==========================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "fig.suptitle('Comparison View', fontsize=18, fontweight='bold')\n",
    "\n",
    "# Original\n",
    "axes[0].imshow(results[\"Original\"])\n",
    "axes[0].set_title(\"Original\", fontsize=14, fontweight='bold')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Model 1\n",
    "axes[1].imshow(results[model1])\n",
    "axes[1].set_title(model1, fontsize=14, fontweight='bold')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Model 2\n",
    "axes[2].imshow(results[model2])\n",
    "axes[2].set_title(model2, fontsize=14, fontweight='bold')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
